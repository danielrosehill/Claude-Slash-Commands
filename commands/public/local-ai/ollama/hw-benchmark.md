I have ollama running on this computer.

Please benchmark my hardware from the perspective of local AI workloads.

What GPU do I have? How much RAM? Give me approximations as to what kind of quantized models I can run on this hardware without imposing undue stress on the machine for other workloads.